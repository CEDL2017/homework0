# homework0
Please write about a deep learning expert in your README.md.
he/she can be a professor (e.g., Yann LeCun), a Ph.D student (e.g., Joseph Chet Redmon), a hacker (e.g., Flood Sung), a researcher (e.g., John Schulman), an enginner (e.g., Soumith Chintala), an entrepreneur (e.g., Matthew Zeiler), etc.
To avoid writing the same person, please report the person's name in  
https://docs.google.com/spreadsheets/d/153XruMO7DPONzBTkxh8ZoYSto1E_2zO021vs0prWZ_Q/edit?usp=sharing
First come first serve!
-------
## Sergey Levine

<img src="https://people.eecs.berkeley.edu/~svlevine/images/portrait_small.png" width="250"/>

&nbsp;&nbsp;&nbsp;&nbsp;Sergey Levine is an assistant professor in the Department of Electrical Engineering and Computer Sciences at UC Berkeley. His research focuses on robotics and machine learning, specifically on the intersection between control and machine learning, with the aim of developing algorithms and techniques that can endow machines with the ability to autonomously acquire the skills for executing complex tasks. In particular, Levine is interested in how learning can be used to acquire complex behavioral skills, in order to endow machines with greater autonomy and intelligence. Applications of his work include autonomous robots and vehicles, as well as computer vision and graphics. His research includes developing algorithms for end-to-end training of deep neural network policies that combine perception and control, scalable algorithms for inverse reinforcement learning, deep reinforcement learning algorithms, and more.

&nbsp;&nbsp;&nbsp;&nbsp;Sergey Levine received a BS and MS in Computer Science from Stanford University in 2009, and a Ph.D. in Computer Science from Stanford University in 2014. He joined the faculty of the Department of Electrical Engineering and Computer Sciences at UC Berkeley in fall 2016. In his PhD thesis, he developed a novel guided policy search algorithm for learning complex neural network control policies, which was later applied to enable a range of robotic tasks, including end-to-end training of policies for perception and control. He has also developed algorithms for learning from demonstration, inverse reinforcement learning, efficient training of stochastic neural networks, computer vision, and data-driven character animation.
